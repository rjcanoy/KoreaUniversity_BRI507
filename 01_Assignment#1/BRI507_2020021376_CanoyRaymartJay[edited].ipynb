{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"BRI507_2020021376_CanoyRaymartJay[edited].ipynb","private_outputs":true,"provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyMTRHj4xNoY3RrdTHz9bqcx"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"watVBTPDsFoO"},"source":["#**Maximum Likelihood Estimation**\n","\n","##**Theory**\n","\n","*   Consider a random sample, which is composed of the variables $X{_1}, \\; X_{2}, \\; ..., X_{m}$. _The probability of each $X_{i}$ is assumed to be dependent on some unknown parameter $\\theta$, and is written as $f(x;\\theta)$, where $x$ is the observed value of the random sample_.  \n","*   In Maximum Likelihood Estimation (MLE), the goal is to **find a point estimator for the unknown parameter** $\\theta$.\n","*   A **good estimate** of the parameter $\\theta$ would be the value of $\\theta$ that **maximizes the probability density (or mass) function**.\n","*   The joint probability density function for every observed random samples $x_{1}, \\; x_{2}, \\; ..., \\; x_{m}$ is given by:\\\\\n","$\n","\\begin{equation}\n","\\begin{gathered}\n","\\begin{alignedat}{1}\n","L(\\theta) &= P(X_{1}=x_{1}, X_{2}=x_{2}, \\; ..., \\; X_{n}=x_{m}) \\\\\n","&= f(x_{1}; \\theta)\\cdot f(x_{2}; \\theta)\\cdot \\cdot \\cdot f(x_{m}; \\theta)\\\\\n","L(\\theta) &= \\prod_{i=1}^{m}f(X_{i}; \\theta)\n","\\end{alignedat}\n","\\end{gathered}\n","\\end{equation}\n","$ \\\\\n","$L(\\theta)$ is also referred to as the \"**likelihood function**\". In MLE, the process involves choosing a parameter $\\theta$ that gives the maximum likelihood of obtaining the observed data.\n","* To make the maximization process easier, the _log likelihood function_ $l(\\theta) = \\ln L(\\theta)$ is often manipulated instead of the complicated likelihood function. This is possible because the natural logarithm is a monotonic increasing function.\n","\n","#**Univariate Normal Distribution**\n","*  The probability density function of $X_{i}$ is \\\\\n","$\\begin{equation}\n","f(x_{i}; \\mu, \\sigma) = \\frac{1}{\\sigma \\sqrt{2\\pi}} \\exp\\left( -\\frac{(x_{i} - \\mu)^{2}}{2\\sigma^{2}} \\right).\n","\\end{equation}\n","$\n","* The likelihood function of the observed random samples is\n","$\\begin{equation}\n","\\begin{gathered}\n","\\begin{alignedat}{1}\n","L(\\mu, \\sigma) &=  \\left[ \\frac{1}{\\sigma \\sqrt{2\\pi}} \\exp\\left( -\\frac{(x_{i} - \\mu)^{2}}{2\\sigma^{2}} \\right) \\right] \\cdot \\cdot \\cdot \\left[ \\frac{1}{\\sigma \\sqrt{2\\pi}} \\exp\\left( -\\frac{(x_{m} - \\mu)^{2}}{2\\sigma^{2}} \\right) \\right] \\\\\n","L(\\mu, \\sigma) &= \\sigma^{-m}(2\\pi)^{-\\frac{m}{2}} \\exp{\\left( -\\sum_{i=1}^{m}{\\frac{(x_{i} - \\mu)^{2}}{2\\sigma^{2}} }\\right)}\n","\\end{alignedat}\n","\\end{gathered}\n","\\end{equation}\n","$\n","* The log likelihood function, therefore, is given by \\\\\n","$\n","\\begin{equation}\n","l(\\mu, \\sigma) = -m\\ln\\sigma -\\frac{m}{2}\\ln (2 \\pi) - \\sum_{i=1}^{m}{\\frac{(x_{i} - \\mu)^{2}}{2\\sigma^{2}}}\n","\\end{equation}\n","$\n","* The maximum likelihood estimor of $\\mu$, therefore, is \\\\\n","$\n","\\begin{equation}\n","\\begin{gathered}\n","\\begin{alignedat}{1}\n","\\frac{\\partial l(\\mu, \\sigma)}{\\partial{\\mu}} &= 0 \\\\\n","-\\sum_{i=1}^{m}{\\frac{2(x_{i} - \\hat{\\mu})(-1)}{2\\sigma^{2}}}  & = 0 \\\\\n","\\sum_{i=1}^{m}{x_{i}} - \\sum_{i=1}^{m}{\\hat{\\mu}} & = 0 \\\\\n","\\hat{\\mu}m &= \\sum_{i=1}^{m}{x_{i}} \\\\\n","\\hat{\\mu} &= \\frac{\\sum_{i=1}^{m}}{m}\n","\\end{alignedat}\n","\\end{gathered}\n","\\end{equation}\n","$\n","* The maximum likelihood estimator of $\\sigma$ \\\\\n","$\n","\\begin{equation}\n","\\begin{gathered}\n","\\begin{alignedat}{1}\n","\\frac{\\partial l(\\mu, \\sigma)}{\\partial{\\sigma}} &= 0 \\\\\n","-m\\left( \\frac{1}{\\hat{\\sigma}}\\right)-\\sum_{i=1}^{m}{\\frac{(x_{i} - \\hat{\\mu})^{2}(-2)}{2\\hat{\\sigma}^{3}}}  & = 0 \\\\\n","m\\hat{\\sigma}^{2} &= \\sum_{i=1}^{m}{\\left(x_{i} - \\mu \\right)^{2}} \\\\\n","\\hat{\\sigma}^{2} &= \\frac{\\sum_{i=1}^{m}{\\left(x_{i} - \\mu \\right)^{2}}}{m}\n","\\end{alignedat}\n","\\end{gathered}\n","\\end{equation}\n","$"]},{"cell_type":"markdown","metadata":{"id":"RZeh5SfSkC35"},"source":["##**Setting up**"]},{"cell_type":"code","metadata":{"id":"VPq73gSpsJRG"},"source":["# Python >= 3.5 is required\n","import sys\n","assert sys.version_info >= (3, 5)\n","\n","# Scikit-Learn >= 0.20 is required\n","import sklearn\n","assert sklearn.__version__ >= \"0.20\"\n","\n","# Common imports\n","import numpy as np\n","import os\n","\n","# Plotting good figures\n","import matplotlib as mpl\n","import matplotlib.pyplot as plt\n","mpl.rc('axes', labelsize=14)\n","mpl.rc('xtick', labelsize=12)\n","mpl.rc('ytick', labelsize=12)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Aa7tFHL-XBpM"},"source":["### **Downloading and reading the Data**\n","* The **[alzheimers_disease_data.csv](https://github.com/rjcanoy03/BRI507)** was uploaded on my Github account.\n","* The **get_data() function** is a basic function which can download and read a _*.csv_ file. \\\\\n","\n","> A. **Arguments**: \n",">> [1] _file_path_: The path containing the _.*csv_ file. The default value is 'https://raw.githubusercontent.com/rjcanoy03/BRI507/'. \\\\\n",">> [2] _file_name_: The filename of the _*.csv_ file. The default value is 'alzheimers_disease_dataset.csv' \\\\\n","\n","> B. **Output** \\\\\n",">> _DataFrame_: A two-dimensional data structure with labeled axes."]},{"cell_type":"code","metadata":{"id":"8H1m5fLsXG0B"},"source":["import os\n","import pandas as pd\n","\n","FILE_ROOT = 'https://raw.githubusercontent.com/rjcanoy03/BRI507/'\n","FILE_PATH = os.path.join(FILE_ROOT, 'main')\n","FILE_NAME = 'alzheimers_disease_dataset.csv'\n","\n","def get_data(file_path=FILE_PATH, file_name=FILE_NAME):\n","  csv_path = os.path.join(file_path, file_name)\n","  print('Downloading and reading', file_name)  \n","  return pd.read_csv(csv_path)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ePTtqMf9SbRa"},"source":["alzheimers_data = get_data()\n","print('')\n","alzheimers_data.head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gJYmI6FieR7m"},"source":["##**Understanding the data**"]},{"cell_type":"code","metadata":{"id":"mVqAQQUNWX_i"},"source":["alzheimers_data.info()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AtQRQJKBg_mu"},"source":["diagnosis_group = {\n","    0 : 'cognitively normal', \n","    1 : 'mild cognitive impairment', \n","    2 : 'Alzheimer''s disease'}\n","\n","print('The total dataset is {}.'.format(alzheimers_data[\"Class\"].count()))\n","print('-'*125)\n","\n","for i in range(0, 3):\n","  #print('i = {}'.format(i))\n","  print('The number of data which is classified as \"{}\" (Class = {}) is {} ({}% of the total dataset).'.format(diagnosis_group[i], i, \\\n","         alzheimers_data[alzheimers_data[\"Class\"] == i]['Class'].count(), \\\n","         round((alzheimers_data[alzheimers_data[\"Class\"] == i]['Class'].count()/alzheimers_data[\"Class\"].count())*100, 2)))\n","  print('')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pBRE9ZiLZomP"},"source":["##**Cognitive Normal (Class = 0)**"]},{"cell_type":"code","metadata":{"id":"kULi1evMHXwd"},"source":["cognitive_normal = {\n","    \"Hippocampus\" : alzheimers_data[alzheimers_data[\"Class\"] == 0][\"Hippocampus\"],\n","    \"Entorhinal\"  : alzheimers_data[alzheimers_data[\"Class\"] == 0][\"Entorhinal\"]}"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4G4rt10Mq3Tk"},"source":["###**[Cognitive  Normal (Case = 0]): Hippocampus (Feature 1)**\n","* In my analysis, the first thing that I intend to do is to guarantee that the data was drawn from a population which follows a normal distribution.\n","* The **normality_test(data)** is a function which performs a normality test using Shapiro-Wilkey test. In Shapiro-Wilkey test, the null hypothesis is:\n",">>$H_{0}$: The data was sampled from a population which follows a normal distribution.\n","\n",">This function utilizes the $scipy.stats.shapiro(x)$, which returns a p-value. If p-value $\\geq$ 0.05, then the data was drawn from a population which follows a normal distribution. However, if p-value $<$ 0.05, then the data MAY NOT be taken from a population which follows a normal distribution.\n","\n","* If the data p-value $<$ 0.05, then these are the succeeding analyses which are done:\n",">>(1.) The data are transformed to their logaithms, and then test again whether or not they now pass the normality test. \\\\\n",">>(2.) If the data still fails the lognormality test, then there may be a few outliers which cause the trouble. Hence, an outlier test is performed."]},{"cell_type":"code","metadata":{"id":"TFOBDxSZ1Q7k"},"source":["import numpy as np\n","from scipy import stats\n","from scipy.stats import shapiro\n","\n","def normality_test(data):\n","  shapiro_test = shapiro(data);\n","  if shapiro_test[1] >= 0.05:\n","    print('Using Shapiro-Wilky Test, the p-value is {}. Therefore, the data was drawn from a normal distribution.'.format(round(shapiro_test[1], 5)))\n","  else:\n","    print('Using Shapiro-Wilky Test, the p-value is {}. Therefore, the data MAY NOT be drawn from a normal distribution'.format(round(shapiro_test[1], 5)))\n","    print('-'*130)\n","    print('Testing for lognormality . . .')\n","    logNorm_shapiro_test = shapiro(np.log(data))\n","    if logNorm_shapiro_test[1] >= 0.05:\n","      print('Using Shapiro-Wilky Test, the p-value is {}. Therefore, the log(data) was drawn from a normal distribution.'.format(round(logNorm_shapiro_test[1], 5)))\n","    else:\n","      print('Using Shapiro-Wilky Test, the p-value is {}. Therefore, the log(data) MAY NOT be drawn from a normal distribution'.format(round(logNorm_shapiro_test[1], 5)))\n","      print('Try performing an outlier test.')\n","\n","\n","print('Cognitive Normal (Class = 0): Hippocampus')\n","print('='*130)\n","normality_test(cognitive_normal[\"Hippocampus\"])\n","print()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"K-h_FRYeWiK5"},"source":["# Visualizing the data through the Q-Q Plot\n","import statsmodels.api as sm\n","\n","# Cognitive Normal (Hippocampus)\n","fig1 = plt.figure(figsize=(15,10))\n","ax1 = fig1.add_subplot(1, 2, 1)\n","sm.graphics.qqplot(cognitive_normal[\"Hippocampus\"], stats.norm, fit = \"True\", line='45', ax=ax1)\n","ax1.set_title('Q-Q Plot (Cognitive Normal [Hippocampus])')\n","ax2 = fig1.add_subplot(1, 2, 2)\n","sm.graphics.qqplot(np.log(cognitive_normal[\"Hippocampus\"]), stats.norm, fit = \"True\", line='45', ax=ax2)\n","ax2.set_title('Q-Q Plot (Cognitive Normal [log(Hippocampus)])')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"L4ND8o0lgQ4r"},"source":["####**Removing the outliers in Cognitive Normal (Hippocampus)**\n","* **Outlier**, in this context, is defined as a data point whose absolute value of z-score is greater than 3."]},{"cell_type":"code","metadata":{"id":"yaj8_UJ-hz2t"},"source":["cognitive_normal_hippocampus_clean = cognitive_normal[\"Hippocampus\"][(stats.zscore(cognitive_normal[\"Hippocampus\"]) <= 3)]\n","print('Now \"cognitive normal\" (Hippocampus) contains {} data elements. Hence, {} elemets had been classified as outlier(s) and removed.'.format(cognitive_normal_hippocampus_clean.count(), \\\n","       cognitive_normal[\"Hippocampus\"].count() - cognitive_normal_hippocampus_clean.count()))\n","print('-'*130)\n","\n","# Normality test\n","normality_test(cognitive_normal_hippocampus_clean)\n","print()\n","\n","# Visualizing the data using Q-Q Plot\n","fig2 = sm.graphics.qqplot(cognitive_normal_hippocampus_clean, stats.norm, fit=True, line='45')\n","fig2.suptitle(\"Q-Q Plot of the cleaned 'cognitive normal' (Hippocampus)\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QFfh0s9dvWm2"},"source":["* Since the data can now be assumed to be taken from a population which follows a normal distribution, then the **maximum likelihood estimators** are \\\\\n","$\n","\\begin{equation}\n","\\begin{gathered}\n","\\begin{alignedat}{1}\n","\\hat{\\mu} &= \\frac{\\sum_{i=1}^{m}{x_{i}}}{m} = \\bar{X}\\\\\n","\\hat{\\sigma}^{2} & = \\frac{\\sum_{i=1}^{m} \\left(x_{i} - \\mu \\right)^{2}}{m} = \\frac{\\sum_{i=1}^{m} \\left(x_{i} - \\bar{X} \\right)^{2}}{m}\n","\\end{alignedat}\n","\\end{gathered}\n","\\end{equation}\n","$\n","\n","* The **univariate_MLE(data)** returns the univariate maximum likelihood estimators $\\hat{\\mu}$ and $\\hat{\\sigma}^{2}$."]},{"cell_type":"code","metadata":{"id":"VKnrlhP-w1_A"},"source":["def univariate_MLE(data):\n","  # Univariate Maximum Likelihood Estimators\n","  mu_hat = np.mean(data)\n","  sigma_squared_hat = np.var(data)\n","  return mu_hat, sigma_squared_hat"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"q9-uPis4yTp3"},"source":["# RAW DATA\n","print(\"RAW DATA\")\n","print(\"=\"*130)\n","[cog_norm_hippo_raw_mu_hat, cog_norm_hippo_raw_var_hat] = univariate_MLE(cognitive_normal[\"Hippocampus\"])\n","print('The maximum likelihood estimators of the Hippocampus of the \"cognitive normal\" diagnostic group are:')\n","print('mu_hat = {},'.format(cog_norm_hippo_raw_mu_hat))\n","print('sigma_square_hat = {}.'.format(cog_norm_hippo_raw_var_hat))\n","print('')\n","print('Note: These are the ML estimators corresponding to the raw data.')\n","print('*'*130)\n","print('')\n","print('')\n","\n","\n","# Cleaned DATA (The data whose z-score values are greater than 3 have been removed)\n","print(\"OUTLIER-ridden DATA\")\n","print(\"=\"*130)\n","[cog_norm_hippo_mu_hat, cog_norm_hippo_var_hat] = univariate_MLE(cognitive_normal_hippocampus_clean)\n","print('The maximum likelihood estimators of the Hippocampus of the \"cognitive normal\" diagnostic group are:')\n","print('mu_hat = {},'.format(cog_norm_hippo_mu_hat))\n","print('sigma_square_hat = {}.'.format(cog_norm_hippo_var_hat))\n","print('')\n","print('Note: These are the ML estimators corresponding to the cleaned data.')\n","print('*'*130)\n","print('')\n","print('')\n","\n","# Visualization\n","fig = plt.figure(figsize=(20,15))\n","ax1 = fig.add_subplot(1, 2, 1)\n","(values, bins1, _) = ax1.hist(cognitive_normal[\"Hippocampus\"], bins = 20, density=True, label='Cognitve Normal (Hippocampus) [RAW]')\n","bin_centers1 = 0.5*(bins1[1:] + bins1[:-1])\n","pdf1 = stats.norm.pdf(x = bin_centers1, loc=cog_norm_hippo_raw_mu_hat, scale=np.sqrt(cog_norm_hippo_raw_var_hat))\n","ax1.plot(bin_centers1, pdf1, label=\"PDF (mu_hat = {}, var_hat = {})\".format(round(cog_norm_hippo_raw_mu_hat, 2), round(cog_norm_hippo_raw_var_hat,2)), color=\"black\", lw=3)\n","ax1.legend()\n","ax1.set_title(\"Cognitively Normal (Hippocampus) [RAW]\", fontsize=15)\n","ax1.set_xlabel('Volume of the Hippocampus for \"cognitive normal\" cases (case=0).', fontsize=15)\n","ax1.set_ylabel('Probability', fontsize=15)\n","ax2 = fig.add_subplot(1, 2, 2)\n","(values, bins2, _) = ax2.hist(cognitive_normal_hippocampus_clean, bins = 20, density=True, label='Cognitve Normal (Hippocampus) [Outlier-ridden Data]')\n","bin_centers2 = 0.5*(bins2[1:] + bins2[:-1])\n","pdf2 = stats.norm.pdf(x = bin_centers2, loc=cog_norm_hippo_mu_hat, scale=np.sqrt(cog_norm_hippo_var_hat))\n","ax2.plot(bin_centers2, pdf2, label=\"PDF (mu_hat = {}, var_hat = {})\".format(round(cog_norm_hippo_mu_hat, 2),round(cog_norm_hippo_var_hat,2)), color=\"black\", lw=3)\n","ax2.legend()\n","ax2.set_title(\"Cognitively Normal (Hippocampus) [Cleaned]\", fontsize=15)\n","ax2.set_xlabel('Volume of the Hippocampus for \"cognitive normal\" cases  (case = 0).', fontsize=15)\n","ax2.set_ylabel('Probability', fontsize=15)\n","plt.show()\n","\n","#fig, fig3 = plt.subplots(ncols=1, nrows=1, figsize=(15, 10))\n","#(values, bins, _) = fig3.hist(cognitive_normal_hippocampus_clean, bins = 20, density=True, label='Cognitve Normal (Hippocampus) [Cleaned]')\n","#bin_centers = 0.5*(bins[1:] + bins[:-1])\n","#pdf = stats.norm.pdf(x = bin_centers, loc=cog_norm_hippo_mu_hat, scale=np.sqrt(cog_norm_hippo_var_hat))\n","#fig3.plot(bin_centers, pdf, label=\"PDF (Using the computed MLEs)\", color=\"black\", lw=3)\n","#fig3.legend()\n","#fig3.set_title(\"Cognitively Normal (Hippocampus) [Cleaned]\", fontsize=15)\n","#fig3.set_xlabel('Volume of the Hippocampus for cases which are diagnosed as \"cognitive normal\".', fontsize=15)\n","#fig3.set_ylabel('Probability', fontsize=15)\n","\n","# Interpretation\n","print('')\n","print(\"Interpretation:\\n\")\n","print('''As can be seen from the plot, these estimators give the maximum likelihood (maximum PDF) of obtaining the data.\n","We can also say that a diagnosis of \"cognitive normal\" can be inferred if the volume of the \n","hippocampus is {} +/- {} for the outlier-ridden data, and {} +/- {} for the raw data.'''.format(round(cog_norm_hippo_mu_hat,2), round(np.sqrt(cog_norm_hippo_var_hat),2), round(cog_norm_hippo_raw_mu_hat,2), round(np.sqrt(cog_norm_hippo_raw_var_hat),2)))\n","print()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nppGIMxU4q20"},"source":["###**[Cognitive Normal (Case = 0)]: Entorhinal Cortex (Feature 2)**\n","\n"]},{"cell_type":"code","metadata":{"id":"RgBaCyzQ7ANE"},"source":["# Normality test\n","print('Cognitive Normal (Class = 0): Entorhinal Cortex')\n","print('='*130)\n","normality_test(cognitive_normal[\"Entorhinal\"])\n","print('*'*130)\n","print()\n","\n","# Visualizing the data using Q-Q Plot\n","fig2 = sm.graphics.qqplot(cognitive_normal[\"Entorhinal\"], stats.norm, fit=True, line='45')\n","fig2.suptitle(\"Q-Q Plot of the'cognitive normal' (Entorhinal Cortex)\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nUoa3CKQ7VPn"},"source":["[cog_norm_ento_mu_hat, cog_norm_ento_var_hat] = univariate_MLE(cognitive_normal[\"Entorhinal\"])\n","print('The maximum likelihood estimators of the Entorhinal Cortex of the \"cognitive normal\" diagnostic group are:')\n","print('mu_hat = {},'.format(cog_norm_ento_mu_hat))\n","print('sigma_square_hat = {}.'.format(cog_norm_ento_var_hat))\n","print('')\n","print('*'*130)\n","print('')\n","print('')\n","\n","# Visualization\n","fig, fig4 = plt.subplots(ncols=1, nrows=1, figsize=(15, 10))\n","(values, bins, _) = fig4.hist(cognitive_normal[\"Entorhinal\"], bins = 30, density=True, label='Cognitve Normal (Entorhinal Cortex)')\n","bin_centers = 0.5*(bins[1:] + bins[:-1])\n","pdf = stats.norm.pdf(x = bin_centers, loc=cog_norm_ento_mu_hat, scale=np.sqrt(cog_norm_ento_var_hat))\n","fig4.plot(bin_centers, pdf, label=\"PDF (Using the computed MLEs)\", color=\"black\", lw=3)\n","fig4.legend()\n","fig4.set_title(\"Cognitively Normal (Entorhinal Cortex)\", fontsize=20)\n","fig4.set_xlabel('Volume of the Entorhinal Cortex for cases which are diagnosed as \"cognitive normal\".', fontsize=15)\n","fig4.set_ylabel('Probability', fontsize=15)\n","\n","# Interpretation\n","print(\"Interpretation:\\n\")\n","print('''As can be seen from the plot, these estimators give the maximum likelihood (maximum PDF) of obtaining the data.\n","We can also say that a diagnosis of \"cognitive normal\" can be inferred if the volume of the \n","entorhinal cortex is {} +/- {}.'''.format(round(cog_norm_ento_mu_hat,2), round(np.sqrt(cog_norm_ento_var_hat),2)))\n","print()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-g--QgN36lay"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"XCEfQuFW-5DZ"},"source":["##**Mild Cognitive Impairment (Class = 1)**"]},{"cell_type":"code","metadata":{"id":"LPNhzcLu_AdQ"},"source":["mild_cognitive_impairment = {\n","    \"Hippocampus\" : alzheimers_data[alzheimers_data[\"Class\"] == 1][\"Hippocampus\"],\n","    \"Entorhinal\"  : alzheimers_data[alzheimers_data[\"Class\"] == 1][\"Entorhinal\"]}"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RMT5b4Iv_fFp"},"source":["###**[Mild Cognitive Impairment (Case = 1)]: Hippocampus (Feature 1)**"]},{"cell_type":"code","metadata":{"id":"SCdrPCkO_kpK"},"source":["# Normality test\n","print('Mild Cognitive Impairment (Class = 1): Hippocampus')\n","print('='*130)\n","normality_test(mild_cognitive_impairment[\"Hippocampus\"])\n","print('*'*130)\n","print()\n","\n","# Visualizing the data using Q-Q Plot\n","fig2 = sm.graphics.qqplot(mild_cognitive_impairment[\"Hippocampus\"], stats.norm, fit=True, line='45')\n","fig2.suptitle(\"Q-Q Plot of the 'mild cognitive impairment' (Hippocampus)\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MXk3hrNuAs62"},"source":["[mild_cog_impair_hippo_mu_hat, mild_cog_impair_hippo_var_hat] = univariate_MLE(mild_cognitive_impairment[\"Hippocampus\"])\n","print('The maximum likelihood estimators of the Hippocampus of the \"mild cognitive impairment\" diagnostic group are:')\n","print('mu_hat = {},'.format(mild_cog_impair_hippo_mu_hat))\n","print('sigma_square_hat = {}.'.format(mild_cog_impair_hippo_var_hat))\n","print('')\n","print('*'*130)\n","print('')\n","print('')\n","\n","# Visualization\n","fig, fig5 = plt.subplots(ncols=1, nrows=1, figsize=(15, 10))\n","(values, bins, _) = fig5.hist(mild_cognitive_impairment[\"Hippocampus\"], bins = 30, density=True, label='Mild Cognitive Impairment (Hippocampus)')\n","bin_centers = 0.5*(bins[1:] + bins[:-1])\n","pdf = stats.norm.pdf(x = bin_centers, loc=mild_cog_impair_hippo_mu_hat, scale=np.sqrt(mild_cog_impair_hippo_var_hat))\n","fig5.plot(bin_centers, pdf, label=\"PDF (Using the computed MLEs)\", color=\"black\", lw=3)\n","fig5.legend()\n","fig5.set_title(\"Mild Cognitive Impairment (Hippocampus)\", fontsize=20)\n","fig5.set_xlabel('Volume of the Hippocampus for cases which are diagnosed as \"mild cognitive impairment\".', fontsize=15)\n","fig5.set_ylabel('Probability', fontsize=15)\n","\n","# Interpretation\n","print(\"Interpretation:\\n\")\n","print('''As can be seen from the plot, these estimators give the maximum likelihood (maximum PDF) of obtaining the data.\n","We can also say that a diagnosis of \"mild cognitive impairment\" can be inferred if the volume of the \n","hippocampus is {} +/- {}.'''.format(round(mild_cog_impair_hippo_mu_hat,2), round(np.sqrt(mild_cog_impair_hippo_var_hat),2)))\n","print()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pQtq2Tb0CB8N"},"source":["###**[Mild Cognitive Impairment (Case = 1)]: Entorhinal Cortex (Feature 2)**"]},{"cell_type":"code","metadata":{"id":"4faVDRmmCQ5k"},"source":["# Normality test\n","print('Mild Cognitive Impairment (Class = 1): Entorhinal')\n","print('='*130)\n","normality_test(mild_cognitive_impairment[\"Entorhinal\"])\n","print('*'*130)\n","print()\n","\n","# Visualizing the data using Q-Q Plot\n","fig2 = sm.graphics.qqplot(mild_cognitive_impairment[\"Entorhinal\"], stats.norm, fit=True, line='45')\n","fig2.suptitle(\"Q-Q Plot of the 'mild cognitive impairment' (Entorhinal Cortex)\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"68tIU5t_Ckyi"},"source":["[mild_cog_impair_ento_mu_hat, mild_cog_impair_ento_var_hat] = univariate_MLE(mild_cognitive_impairment[\"Entorhinal\"])\n","print('The maximum likelihood estimators of the Entorhinal Cortex of the \"mild cognitive impairment\" diagnostic group are:')\n","print('mu_hat = {},'.format(mild_cog_impair_ento_mu_hat))\n","print('sigma_square_hat = {}.'.format(mild_cog_impair_ento_var_hat))\n","print('')\n","print('*'*130)\n","print('')\n","print('')\n","\n","# Visualization\n","fig, fig6 = plt.subplots(ncols=1, nrows=1, figsize=(15, 10))\n","(values, bins, _) = fig6.hist(mild_cognitive_impairment[\"Entorhinal\"], bins = 30, density=True, label='Mild Cognitive Impairment (Entorhinal Cortex)')\n","bin_centers = 0.5*(bins[1:] + bins[:-1])\n","pdf = stats.norm.pdf(x = bin_centers, loc=mild_cog_impair_ento_mu_hat, scale=np.sqrt(mild_cog_impair_ento_var_hat))\n","fig6.plot(bin_centers, pdf, label=\"PDF (Using the computed MLEs)\", color=\"black\", lw=3)\n","fig6.legend()\n","fig6.set_title(\"Mild Cognitive Impairment (Entorhinal Cortex)\", fontsize=20)\n","fig6.set_xlabel('Volume of the Entorhinal Cortex for cases which are diagnosed as \"mild cognitive impairment\".', fontsize=15)\n","fig6.set_ylabel('Probability', fontsize=15)\n","\n","# Interpretation\n","print(\"Interpretation:\\n\")\n","print('''As can be seen from the plot, these estimators give the maximum likelihood (maximum PDF) of obtaining the data.\n","We can also say that a diagnosis of \"mild cognitive impairment\" can be inferred if the volume of the \n","entorhinal cortex is {} +/- {}.'''.format(round(mild_cog_impair_ento_mu_hat,2), round(np.sqrt(mild_cog_impair_ento_var_hat),2)))\n","print()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KnRMQN3jDsJc"},"source":["##**Alzheimer's Disease (Case = 2)**"]},{"cell_type":"code","metadata":{"id":"7OBJPJTXEEe7"},"source":["alzheimers_disease = {\n","    \"Hippocampus\" : alzheimers_data[alzheimers_data[\"Class\"] == 2][\"Hippocampus\"],\n","    \"Entorhinal\"  : alzheimers_data[alzheimers_data[\"Class\"] == 2][\"Entorhinal\"]}"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lcBbPrbEDzj_"},"source":["###**[Alzheimer's Disease (Case = 2)]: Hippocampus (Feature 1)**"]},{"cell_type":"code","metadata":{"id":"MlPurqy_DuG4"},"source":["# Normality test\n","print('Alzheimer''s Disease (Class = 2): Hippocampus')\n","print('='*130)\n","normality_test(alzheimers_disease[\"Hippocampus\"])\n","print('*'*130)\n","print()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cXRHVeBnDlzv"},"source":["# Alzheimer's disease (Hippocampus)\n","fig1 = plt.figure(figsize=(15,10))\n","ax1 = fig1.add_subplot(1, 2, 1)\n","sm.graphics.qqplot(alzheimers_disease[\"Hippocampus\"], stats.norm, fit = \"True\", line='45', ax=ax1)\n","ax1.set_title('Q-Q Plot (Alzheimer''s disease [Hippocampus])')\n","ax2 = fig1.add_subplot(1, 2, 2)\n","sm.graphics.qqplot(np.log(alzheimers_disease[\"Hippocampus\"]), stats.norm, fit = \"True\", line='45', ax=ax2)\n","ax2.set_title('Q-Q Plot (Alzheimer''s disease [log(Hippocampus)])')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xqWJxefKGfcL"},"source":["alzheimers_disease_hippocampus_clean = alzheimers_disease[\"Hippocampus\"][(stats.zscore(alzheimers_disease[\"Hippocampus\"]) <= 3)]\n","print('Now \"cognitive normal\" (Hippocampus) contains {} data elements. Hence, {} elemets had been classified as outlier(s) and removed.'.format(alzheimers_disease_hippocampus_clean.count(), \\\n","       alzheimers_disease[\"Hippocampus\"].count() - alzheimers_disease_hippocampus_clean.count()))\n","print('-'*130)\n","\n","# Normality test\n","normality_test(alzheimers_disease_hippocampus_clean)\n","print()\n","\n","# Visualizing the data using Q-Q Plot\n","fig2 = sm.graphics.qqplot(alzheimers_disease_hippocampus_clean, stats.norm, fit=True, line='45')\n","fig2.suptitle(\"Q-Q Plot of the cleaned 'Alzheimer's disease' (Hippocampus)\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GteKojSeHmCG"},"source":["* **Even after removing the outlier, the data still fails the normality test.**\n","* But it is important to take note that the **logarithms of the data** pass the normality test. Hence, for the volume of the hippocampus for cases which are classified as \"alzheimer's disease\", I will be using the logarithms of the data for the analysis. "]},{"cell_type":"code","metadata":{"id":"a1Hz0tLHIomE"},"source":["alzheimers_disease_hippocampus_log = np.log(alzheimers_disease[\"Hippocampus\"])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"y-I-rKBKI5_s"},"source":["# RAW DATA\n","print(\"RAW DATA\")\n","print(\"=\"*130)\n","[ad_hippo_raw_mu_hat, ad_hippo_raw_var_hat] = univariate_MLE(alzheimers_disease[\"Hippocampus\"])\n","print('The maximum likelihood estimators of the Hippocampus of the \"Alzheimer''s\" diagnostic group are:')\n","print('mu_hat = {},'.format(ad_hippo_raw_mu_hat))\n","print('sigma_square_hat = {}.'.format(ad_hippo_raw_var_hat))\n","print('')\n","print('Note: These are the ML estimators corresponding to the raw data.')\n","print('*'*130)\n","print('')\n","print('')\n","\n","# Log-transformed Data\n","print(\"Log-transformed DATA\")\n","print(\"=\"*130)\n","[ad_hippo_log_mu_hat, ad_hippo_log_var_hat] = univariate_MLE(alzheimers_disease_hippocampus_log)\n","print('The maximum likelihood estimators of the Hippocampus of the \"Alzheimer''s disease\" diagnostic group are:')\n","print('mu_hat = {},'.format(np.exp(ad_hippo_log_mu_hat)))\n","print('sigma_square_hat = {}.'.format(np.exp(ad_hippo_log_var_hat)))\n","print('')\n","print('Note: These are the ML estimators corresponding to the log-transformed data.')\n","print('*'*130)\n","print('')\n","print('')\n","\n","# Visualization\n","fig = plt.figure(figsize=(20,15))\n","ax1 = fig.add_subplot(1, 2, 1)\n","(values, bins1, _) = ax1.hist(alzheimers_disease[\"Hippocampus\"], bins = 20, density=True, label='Alzheimer''s Disease (Hippocampus) [RAW]')\n","bin_centers1 = 0.5*(bins1[1:] + bins1[:-1])\n","pdf1 = stats.norm.pdf(x = bin_centers1, loc=ad_hippo_raw_mu_hat, scale=np.sqrt(ad_hippo_raw_var_hat))\n","ax1.plot(bin_centers1, pdf1, label=\"PDF (mu_hat = {}, var_hat = {})\".format(round(ad_hippo_raw_mu_hat, 2), round(ad_hippo_raw_var_hat,2)), color=\"black\", lw=3)\n","ax1.legend()\n","ax1.set_title(\"Alzheimer's Disease (Hippocampus) [RAW]\", fontsize=15)\n","ax1.set_xlabel('Volume of the Hippocampus for \"Alzheimer''s Disease\" cases (case=2).', fontsize=15)\n","ax1.set_ylabel('Probability', fontsize=15)\n","ax2 = fig.add_subplot(1, 2, 2)\n","(values, bins2, _) = ax2.hist(alzheimers_disease_hippocampus_log, bins = 20, density=True, label='ALzheimer'' Disease (Hippocampus) [Log-transformed Data]')\n","bin_centers2 = 0.5*(bins2[1:] + bins2[:-1])\n","pdf2 = stats.norm.pdf(x = bin_centers2, loc=ad_hippo_log_mu_hat, scale=np.sqrt(ad_hippo_log_var_hat))\n","ax2.plot(bin_centers2, pdf2, label=\"PDF (mu_hat = {}, var_hat = {})\".format(round(ad_hippo_log_mu_hat, 2),round(ad_hippo_log_var_hat,2)), color=\"black\", lw=3)\n","ax2.legend()\n","ax2.set_title(\"Alzheimer's Disease (Hippocampus) [Log-transformed Data]\", fontsize=15)\n","ax2.set_xlabel('Log-Volume of the Hippocampus for \"Alzheimer'' Disease\" cases  (case = 2).', fontsize=15)\n","ax2.set_ylabel('Probability', fontsize=15)\n","plt.show()\n","\n","# Visualization\n","#fig, fig7 = plt.subplots(ncols=1, nrows=1, figsize=(15, 10))\n","#(values, bins, _) = fig7.hist(alzheimers_disease_hippocampus_log, bins = 30, density=True, label='Alzheimer''s disease (Hippocampus)')\n","#bin_centers = 0.5*(bins[1:] + bins[:-1])\n","#pdf = stats.norm.pdf(x = bin_centers, loc=ad_hippo_log_mu_hat, scale=np.sqrt(ad_hippo_log_var_hat))\n","#fig7.plot(bin_centers, pdf, label=\"PDF (Using the computed MLEs)\", color=\"black\", lw=3)\n","#fig7.legend()\n","#fig7.set_title(\"Alzheimer's Disease (Hippocampus)\", fontsize=20)\n","#fig7.set_xlabel('Natural logarithm of the volume of the Hippocampus for cases which are diagnosed as \"alzheimer''s disease\".', fontsize=15)\n","#fig7.set_ylabel('Probability', fontsize=15)\n","\n","# Interpretation\n","print(\"Interpretation:\\n\")\n","print('''As can be seen from the plot, these estimators give the maximum likelihood (maximum PDF) of obtaining the data.\n","We can also say that a diagnosis of \"alzheimer's disease\" can be inferred if the volume of the \n","hippocampus is {} +/- {} for the log-transformed data, and {} +/- {} for the raw data.'''.format(round(np.exp(ad_hippo_log_mu_hat),2), round(np.sqrt(np.exp(ad_hippo_log_var_hat)),2), \\\n","      round(ad_hippo_raw_mu_hat, 2), round(np.sqrt(ad_hippo_raw_var_hat))))\n","print()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"K-F-5reNLOSo"},"source":["###**[Alzheimer's Disease (Case = 2)]: Entorhinal Cortex (Feature 2)**"]},{"cell_type":"code","metadata":{"id":"843g-5sILanN"},"source":["# Normality test\n","print('Alzheimer''s Disease (Class = 2): Entorhinal')\n","print('='*130)\n","normality_test(alzheimers_disease[\"Entorhinal\"])\n","print('*'*130)\n","print()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RoAPGdIkL1ha"},"source":["# Alzheimer's disease (Entorhinal Cortex)\n","fig1 = plt.figure(figsize=(15,10))\n","ax1 = fig1.add_subplot(1, 2, 1)\n","sm.graphics.qqplot(alzheimers_disease[\"Entorhinal\"], stats.norm, fit = \"True\", line='45', ax=ax1)\n","ax1.set_title('Q-Q Plot (Alzheimer''s disease [Entorhinal Cortex])')\n","ax2 = fig1.add_subplot(1, 2, 2)\n","sm.graphics.qqplot(np.log(alzheimers_disease[\"Entorhinal\"]), stats.norm, fit = \"True\", line='45', ax=ax2)\n","ax2.set_title('Q-Q Plot (Alzheimer''s disease [log(Entorhinal Cortex)])')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wC0o1ZtjMenA"},"source":["* For the volume of the entorhinal cortex for cases which are classified as \"alzheimer's disease\", I will also be using the logarithms of the data for the analysis. "]},{"cell_type":"code","metadata":{"id":"6bHomkzHMRuJ"},"source":["alzheimers_disease_entorhinal_log = np.log(alzheimers_disease[\"Entorhinal\"])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7Vb9G9YhMouG"},"source":["# RAW DATA\n","print(\"RAW DATA\")\n","print(\"=\"*130)\n","[ad_ento_raw_mu_hat, ad_ento_raw_var_hat] = univariate_MLE(alzheimers_disease[\"Entorhinal\"])\n","print('The maximum likelihood estimators of the Entorhinal Cortex of the \"Alzheimer''s\" diagnostic group are:')\n","print('mu_hat = {},'.format(ad_ento_raw_mu_hat))\n","print('sigma_square_hat = {}.'.format(ad_ento_raw_var_hat))\n","print('')\n","print('Note: These are the ML estimators corresponding to the raw data.')\n","print('*'*130)\n","print('')\n","print('')\n","\n","# Log-transformed Data\n","print(\"Log-transformed DATA\")\n","print(\"=\"*130)\n","[ad_ento_log_mu_hat, ad_ento_log_var_hat] = univariate_MLE(alzheimers_disease_entorhinal_log)\n","print('The maximum likelihood estimators of the Entorhinal Cortex of the \"alzheimer'' disease\" diagnostic group are:')\n","print('mu_hat = {},'.format(np.exp(ad_ento_log_mu_hat)))\n","print('sigma_square_hat = {}.'.format(np.exp(ad_ento_log_var_hat)))\n","print('')\n","print('*'*130)\n","print('')\n","print('')\n","\n","\n","# Visualization\n","fig = plt.figure(figsize=(20,15))\n","ax1 = fig.add_subplot(1, 2, 1)\n","(values, bins1, _) = ax1.hist(alzheimers_disease[\"Entorhinal\"], bins = 20, density=True, label='Alzheimer''s Disease (Entorhinal) [RAW]')\n","bin_centers1 = 0.5*(bins1[1:] + bins1[:-1])\n","pdf1 = stats.norm.pdf(x = bin_centers1, loc=ad_ento_raw_mu_hat, scale=np.sqrt(ad_ento_raw_var_hat))\n","ax1.plot(bin_centers1, pdf1, label=\"PDF (mu_hat = {}, var_hat = {})\".format(round(ad_ento_raw_mu_hat, 2), round(ad_ento_raw_var_hat,2)), color=\"black\", lw=3)\n","ax1.legend()\n","ax1.set_title(\"Alzheimer's Disease (Entorhinal Cortex) [RAW]\", fontsize=15)\n","ax1.set_xlabel('Volume of the Entorhinal for \"Alzheimer''s Disease\" cases (case=2).', fontsize=15)\n","ax1.set_ylabel('Probability', fontsize=15)\n","ax2 = fig.add_subplot(1, 2, 2)\n","(values, bins2, _) = ax2.hist(alzheimers_disease_entorhinal_log, bins = 20, density=True, label='ALzheimer'' Disease (Entorhinal) [Log-transformed Data]')\n","bin_centers2 = 0.5*(bins2[1:] + bins2[:-1])\n","pdf2 = stats.norm.pdf(x = bin_centers2, loc=ad_ento_log_mu_hat, scale=np.sqrt(ad_ento_log_var_hat))\n","ax2.plot(bin_centers2, pdf2, label=\"PDF (mu_hat = {}, var_hat = {})\".format(round(ad_ento_log_mu_hat, 2),round(ad_ento_log_var_hat,2)), color=\"black\", lw=3)\n","ax2.legend()\n","ax2.set_title(\"Alzheimer's Disease (Entorhinal Cortex) [Log-transformed Data]\", fontsize=15)\n","ax2.set_xlabel('Log-Volume of the Entorhinal for \"Alzheimer'' Disease\" cases  (case = 2).', fontsize=15)\n","ax2.set_ylabel('Probability', fontsize=15)\n","plt.show()\n","\n","# Visualization\n","#fig, fig8 = plt.subplots(ncols=1, nrows=1, figsize=(15, 10))\n","#(values, bins, _) = fig8.hist(alzheimers_disease_entorhinal_log, bins = 30, density=True, label='Alzheimer''s disease (Entorhinal Cortex)')\n","#bin_centers = 0.5*(bins[1:] + bins[:-1])\n","#pdf = stats.norm.pdf(x = bin_centers, loc=ad_ento_log_mu_hat, scale=np.sqrt(ad_ento_log_var_hat))\n","#fig8.plot(bin_centers, pdf, label=\"PDF (Using the computed MLEs)\", color=\"black\", lw=3)\n","#fig8.legend()\n","#fig8.set_title(\"Alzheimer's Disease (Entorhinal Cortex)\", fontsize=20)\n","#fig8.set_xlabel('Natural logarithm of the volume of the Entorhinal Cortex for cases which are diagnosed as \"alzheimer''s disease\".', fontsize=15)\n","#fig8.set_ylabel('Probability', fontsize=15)\n","\n","# Interpretation\n","print(\"Interpretation:\\n\")\n","print('''As can be seen from the plot, these estimators give the maximum likelihood (PDF) of obtaining the data.\n","We can also say that a diagnosis of \"alzheimer's disease\" can be inferred if the volume of the \n","entorhinal cortex is {} +/- {} for the log-transformed data, and {} +/- {} for the raw data.'''.format(round(np.exp(ad_ento_log_mu_hat),2), round(np.sqrt(np.exp(ad_ento_log_var_hat)),2), \\\n","      round(ad_ento_raw_mu_hat, 2), round(np.sqrt(ad_ento_raw_var_hat))))\n","print()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dAkVXAr0OE01"},"source":["##**Summary**\n"]},{"cell_type":"code","metadata":{"id":"K4_UxBKuOQ0c"},"source":["print('RAW DATa')\n","print('='*180)\n","summary_raw = pd.DataFrame({'Cases': ['Cognitive Normal (Case = 0)', 'Mild Cognirtive Impairment (Case = 1)', 'Alzheimer'' Disease (Case = 2)']})\n","summary_raw['Hippocampus (mu_hat)'] = [cog_norm_hippo_raw_mu_hat, mild_cog_impair_hippo_mu_hat, ad_hippo_raw_mu_hat]\n","summary_raw['Hippocampus (sigma_squared_hat)']  = [cog_norm_hippo_raw_var_hat, mild_cog_impair_hippo_var_hat, ad_hippo_log_var_hat]\n","summary_raw['Entorhinal Cortex (mu_hat)'] = [cog_norm_ento_mu_hat, mild_cog_impair_ento_mu_hat, ad_ento_raw_mu_hat]\n","summary_raw['Entorhinal Cortex (sigma_squared_hat)']  = [cog_norm_ento_var_hat, mild_cog_impair_ento_var_hat, ad_ento_raw_var_hat]\n","summary_raw.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gv6V_6KC9Ie-"},"source":["print('Those data who failed the normality test were either rid-offed outliers or transformed into their logarithms.')\n","print('='*180)\n","summary = pd.DataFrame({'Cases': ['Cognitive Normal (Case = 0)', 'Mild Cognirtive Impairment (Case = 1)', 'Alzheimer'' Disease (Case = 2)']})\n","summary['Hippocampus (mu_hat)'] = [cog_norm_hippo_mu_hat, mild_cog_impair_hippo_mu_hat, np.exp(ad_hippo_log_mu_hat)]\n","summary['Hippocampus (sigma_squared_hat)']  = [cog_norm_hippo_var_hat, mild_cog_impair_hippo_var_hat, np.exp(ad_hippo_log_var_hat)]\n","summary['Entorhinal Cortex (mu_hat)'] = [cog_norm_ento_mu_hat, mild_cog_impair_ento_mu_hat, np.exp(ad_ento_log_mu_hat)]\n","summary['Entorhinal Cortex (sigma_squared_hat)']  = [cog_norm_ento_var_hat, mild_cog_impair_ento_var_hat, np.exp(ad_ento_log_var_hat)]\n","summary.head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eoltKcW7VszB"},"source":["###**Conclusion**\n","As the disease progresses from cognitive normal, mild cognitive impairment to Alzheimer's disease, the **volumes of both the hippocampus and entorhinal cortex also shrink as well**."]},{"cell_type":"markdown","metadata":{"id":"4n8Ee57sWl91"},"source":["#**Multivariate  Normal Distribution**\n","* The normal distribution of a random vector $\\mathbf{x}$ in $\\mathbb{R}^{d}$ is \\\\\n","$\n","\\begin{equation}\n","P(\\mathbf{x}; \\mathbf{\\mu}, \\mathbf{\\Sigma}) = \\frac{1}{(2\\pi)^{d/2}} |\\mathbf{\\Sigma}|^{-\\frac{1}{2}} \\exp \\left( -\\frac{1}{2} (\\mathbf{x} - \\mathbf{\\mu})\\Sigma^{-1}(\\mathbf{x} - \\mu)^{T} \\right),\n","\\end{equation}\n","$\n","where the factor $\\frac{1}{(2\\pi)^{d/2}} |\\mathbf{\\Sigma}|^{-\\frac{1}{2}}$ ensures that the PDF integrates to one.\n","\n","* The maximum likelihood estimator for $\\mathbf{\\mu}$ is \\\\\n","$\n","\\begin{equation}\n","\\hat{\\mathbf{\\mu}} = \\frac{\\sum_{i=1}^{m}{\\mathbf{x}_{i}}}{m}\n","\\end{equation}\n","$\n","\n","* The maximum likelihood estimator for the covariance $\\mathbf{\\Sigma}$ is \\\\\n","$\n","\\begin{equation}\n","\\hat{\\mathbf{\\Sigma}} = \\frac{\\sum_{i=1}^{m}{(\\mathbf{x}_{i} - \\mathbf{\\mu})(\\mathbf{x}_{i} - \\mathbf{\\mu})^{T}}}{m}\n","\\end{equation}\n","$\n","* **For this section, I will assume that the random samples were taken from a population which follows a normal distribution. Hence, I won't be performing a normality test in this section.**"]},{"cell_type":"markdown","metadata":{"id":"DOlxF3aQtblA"},"source":["**Note**\n","> (1.) The function **var_cov(feature1, feature2)** returns an array which contains the maximum likelihood estimator $\\mathbf{\\Sigma}.$\n",">> * Although I am aware that there is an **np.cov()** function which performs exactly the same task, yet I still decided to make my own function to get myself familiarize with Python. \\\\\n",">> * _Kindly note also that there is a little discrepancy between my var_cov(feature1, feature2) function and Python's np.cov() function._\n"," \n","> (2.) The **multivariate_MLE(feature1, feature2)** accepts two variables and return the maximum likelihood estimators for this bivariate distribution.\n"]},{"cell_type":"code","metadata":{"id":"RbREpZ2eVPuq"},"source":["def var_cov(feature1, feature2):\n","  if len(feature1) == len(feature2):\n","    feature1_mean_subtracted = feature1 - np.mean(feature1)\n","    feature2_mean_subtracted = feature2 - np.mean(feature2)\n","    # A matrix X which holds the variables is constructed next\n","    # The row of the matrix X corresponds to the variable (feature)\n","    # The colum corresponds to the data points\n","    X = (pd.concat([feature1_mean_subtracted, feature2_mean_subtracted], axis = 1)).T\n","    return (X.dot(X.T))/len(feature1)\n","  else:\n","    print('The dimensions of feature1 and feature2 should be the same.')\n","\n","\n","def multivariate_MLE(feature1, feature2):\n","  mu = [[np.mean(feature1)], [np.mean(feature2)]]\n","  Sigma = var_cov(feature1, feature2)\n","  return np.array(mu), np.array(Sigma)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Rv5XJgzGyt-b"},"source":["##**Cognitive Normal (Class = 0)**"]},{"cell_type":"code","metadata":{"id":"fjIpcI5CwBY4"},"source":["# Calculating for the maximum likelihood estimators for the diagnostic group \"cognitive normal\" (Case = 0)\n","[cog_norm_mult_mu, cog_norm_mult_Sigma] = multivariate_MLE(cognitive_normal[\"Hippocampus\"], cognitive_normal[\"Entorhinal\"])\n","\n","print('The maximum likelihood estimator mu:')\n","print('')\n","print('mu =', cog_norm_mult_mu)\n","print('-'*130)\n","print('The maximum likelihood estimor Sigma, which is computed using var_cov():')\n","print('')\n","print('Sigma =', cog_norm_mult_Sigma)\n","print('-'*130)\n","print('The maximum likelihood estimator Sigma, which is computed using Python''s np.cov()')\n","print('')\n","cog_norm_mult_Sigma_npCOV = np.cov(pd.concat([cognitive_normal[\"Hippocampus\"], cognitive_normal[\"Entorhinal\"]], axis=1).T)\n","print('Sigma (computed using np.cov) = ', cog_norm_mult_Sigma_npCOV)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2_bbuEthuAP4"},"source":["####**Scatter Plot of the Alzheimer's Dataset**\n","* I showed here the scatter plot of the entire dataset to visualize how the classes are clustered together.\n","* From the plot, it is easy to see that the distance of the centroid of each class is very near each other.\n","* For now, the scatter plot provides a very little information on how the classes are clustered together with respect to both the volumes of the hippocampus and entorhinal cortex."]},{"cell_type":"code","metadata":{"id":"B2sVsN9grsQ1"},"source":["import seaborn as sns\n","\n","sns.jointplot(x=\"Hippocampus\", y=\"Entorhinal\", data=alzheimers_data, kind=\"scatter\", hue=\"Class\", height=8)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"elfWE-Jww6Di"},"source":["####**Contour Density Plot**\n","* However, if we look at the contour density plot, it is easy to see that at the values of the maximum likelihood estimator $\\mathbf{\\mu}$, the density or the probability density function for both the volumes of the hippocampus and entorhinal are maximum."]},{"cell_type":"code","metadata":{"id":"l5LZKwE8-EqJ"},"source":["cdp1 = sns.jointplot(x=\"Hippocampus\", y=\"Entorhinal\", data=cognitive_normal, height=13,marginal_ticks=True)\n","cdp1.plot_joint(sns.kdeplot, color=\"r\", zorder=0, levels=6)\n","cdp1.plot_marginals(sns.rugplot, color=\"r\", height=-.10, clip_on=False)\n","cdp1.ax_joint.plot([3000,11500], [cog_norm_mult_mu[1],cog_norm_mult_mu[1]], 'k--', linewidth = 2)\n","cdp1.ax_joint.plot([cog_norm_mult_mu[0],cog_norm_mult_mu[0]], [1000,6500], 'k--', linewidth=2)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8gY8_d7Zw42h"},"source":["###**Looking at the three-dimensional plot of the probability function, it is easy to see that the maximum likelihood estimators, $\\mathbf{\\mu}$ and $\\mathbf{\\Sigma}$, give the maximum likelihood (PDF) of obtaining the multivariate data.**\n","\n","Note: The same interpretation should apply to \"mild cognitive impairment\" and \"alzheimer's disease\" data."]},{"cell_type":"code","metadata":{"id":"CvukmVDz-avj"},"source":["from scipy.stats import multivariate_normal\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from mpl_toolkits.mplot3d import axes3d\n","\n","# Setting up the grid\n","x, y = np.mgrid[2000:12000:1, 1000:6000:1]\n","pos = np.dstack((x, y))\n","pos2 = np.dstack((cognitive_normal[\"Hippocampus\"], cognitive_normal[\"Entorhinal\"]))\n","rv = multivariate_normal([np.mean(cognitive_normal[\"Hippocampus\"]), np.mean(cognitive_normal[\"Entorhinal\"])], cog_norm_mult_Sigma)\n","\n","# Three-dimensional Plot\n","fig = plt.figure(figsize=(15,10))\n","ax = fig.add_subplot(111, projection='3d')\n","ax.plot_wireframe(x, y, rv.pdf(pos), rstride=10, cstride=10, alpha=0.05, label='PDF (Calculated using the MLEs)')\n","ax.scatter(cognitive_normal[\"Hippocampus\"], cognitive_normal[\"Entorhinal\"], rv.pdf(pos2), c='k', label='PDF (Corresponding to the Data)')\n","ax.legend()\n","ax.set_xlabel('Hippocampus', fontsize=15)\n","ax.set_ylabel('Entorhinal Cortex', fontsize=15)\n","ax.set_zlabel('Probability', fontsize=15)\n","ax.set_title('Cognitive Normal (Case = 0)', fontsize=24)\n","plt.show()\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"54qpxMPBnWPS"},"source":["##**Mild Cognitive Impairment (Case = 1)**\n"]},{"cell_type":"code","metadata":{"id":"SoLgk19pnh9i"},"source":["# Calculating for the maximum likelihood estimators for the diagnostic group \"mild cognitive impairment\" (Case = 1)\n","[mild_cog_impair_mult_mu, mild_cog_impair_mult_Sigma] = multivariate_MLE(mild_cognitive_impairment[\"Hippocampus\"], mild_cognitive_impairment[\"Entorhinal\"])\n","\n","print('The maximum likelihood estimator mu:')\n","print('')\n","print('mu =', mild_cog_impair_mult_mu)\n","print('-'*130)\n","print('The maximum likelihood estimor Sigma, which is computed using var_cov():')\n","print('')\n","print('Sigma =', mild_cog_impair_mult_Sigma)\n","print('-'*130)\n","print('The maximum likelihood estimator Sigma, which is computed using Python''s np.cov()')\n","print('')\n","mild_cog_impair_mult_Sigma_npCOV = np.cov(pd.concat([mild_cognitive_impairment[\"Hippocampus\"], mild_cognitive_impairment[\"Entorhinal\"]], axis=1).T)\n","print('Sigma (computed using np.cov) = ', mild_cog_impair_mult_Sigma_npCOV)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-Ja2xtF87ZZ4"},"source":["cdp1 = sns.jointplot(x=\"Hippocampus\", y=\"Entorhinal\", data=mild_cognitive_impairment, height=13,marginal_ticks=True)\n","cdp1.plot_joint(sns.kdeplot, color=\"r\", zorder=0, levels=6)\n","cdp1.plot_marginals(sns.rugplot, color=\"r\", height=-.10, clip_on=False)\n","cdp1.ax_joint.plot([3000,11500], [mild_cog_impair_mult_mu[1],mild_cog_impair_mult_mu[1]], 'k--', linewidth = 2)\n","cdp1.ax_joint.plot([mild_cog_impair_mult_mu[0],mild_cog_impair_mult_mu[0]], [1000,6000], 'k--', linewidth=2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2_qg4VsG0_jj"},"source":["from scipy.stats import multivariate_normal\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from mpl_toolkits.mplot3d import axes3d\n","\n","# Setting up the grid\n","x, y = np.mgrid[2000:12000:1, 1000:6000:1]\n","pos = np.dstack((x, y))\n","pos2 = np.dstack((mild_cognitive_impairment[\"Hippocampus\"], mild_cognitive_impairment[\"Entorhinal\"]))\n","rv = multivariate_normal([np.mean(mild_cognitive_impairment[\"Hippocampus\"]), np.mean(mild_cognitive_impairment[\"Entorhinal\"])], mild_cog_impair_mult_Sigma)\n","\n","# Three-dimensional Plot\n","fig = plt.figure(figsize=(15,10))\n","ax = fig.add_subplot(111, projection='3d')\n","ax.plot_wireframe(x, y, rv.pdf(pos), rstride=10, cstride=10, alpha=0.05, label='PDF (Calculated using the MLEs)')\n","ax.scatter(mild_cognitive_impairment[\"Hippocampus\"], mild_cognitive_impairment[\"Entorhinal\"], rv.pdf(pos2), c='k', label='PDF (Corresponding to the Data)')\n","ax.legend()\n","ax.set_xlabel('Hippocampus', fontsize=15)\n","ax.set_ylabel('Entorhinal Cortex', fontsize=15)\n","ax.set_zlabel('Probability', fontsize=15)\n","ax.set_title('Mild Cognitive Impairment (Case = 1)', fontsize=24)\n","plt.show()\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"c0pROrokoNnt"},"source":["##**Alzheimer's Disease (Case = 2)**"]},{"cell_type":"code","metadata":{"id":"cRRdfv79oT6Q"},"source":["# Calculating for the maximum likelihood estimators for the diagnostic group \"alzheimer's disease\" (Case = 2)\n","[ad_mult_mu, ad_mult_Sigma] = multivariate_MLE(alzheimers_disease[\"Hippocampus\"], alzheimers_disease[\"Entorhinal\"])\n","\n","print('The maximum likelihood estimator mu:')\n","print('')\n","print('mu =', ad_mult_mu)\n","print('-'*130)\n","print('The maximum likelihood estimor Sigma, which is computed using var_cov():')\n","print('')\n","print('Sigma =', ad_mult_Sigma)\n","print('-'*130)\n","print('The maximum likelihood estimator Sigma, which is computed using Python''s np.cov()')\n","print('')\n","ad_mult_Sigma_npCOV = np.cov(pd.concat([alzheimers_disease[\"Hippocampus\"], alzheimers_disease[\"Entorhinal\"]], axis=1).T)\n","print('Sigma (computed using np.cov) = ', ad_mult_Sigma_npCOV)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uFBizKrD8L2f"},"source":["cdp1 = sns.jointplot(x=\"Hippocampus\", y=\"Entorhinal\", data=alzheimers_disease, height=13,marginal_ticks=True)\n","cdp1.plot_joint(sns.kdeplot, color=\"r\", zorder=0, levels=6)\n","cdp1.plot_marginals(sns.rugplot, color=\"r\", height=-.10, clip_on=False)\n","cdp1.ax_joint.plot([2000,11500], [ad_mult_mu[1],ad_mult_mu[1]], 'k--', linewidth = 2)\n","cdp1.ax_joint.plot([ad_mult_mu[0],ad_mult_mu[0]], [1000,6000], 'k--', linewidth=2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tH6p11eS7LtX"},"source":["from scipy.stats import multivariate_normal\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from mpl_toolkits.mplot3d import axes3d\n","\n","# Setting up the grid\n","x, y = np.mgrid[2000:12000:1, 1000:6000:1]\n","pos = np.dstack((x, y))\n","pos2 = np.dstack((alzheimers_disease[\"Hippocampus\"], alzheimers_disease[\"Entorhinal\"]))\n","rv = multivariate_normal([np.mean(alzheimers_disease[\"Hippocampus\"]), np.mean(alzheimers_disease[\"Entorhinal\"])], ad_mult_Sigma)\n","\n","# Three-dimensional Plot\n","fig = plt.figure(figsize=(15,10))\n","ax = fig.add_subplot(111, projection='3d')\n","ax.plot_wireframe(x, y, rv.pdf(pos), rstride=10, cstride=10, alpha=0.05, label='PDF (Calculated using the MLEs)')\n","ax.scatter(alzheimers_disease[\"Hippocampus\"], alzheimers_disease[\"Entorhinal\"], rv.pdf(pos2), c='k', label='PDF (Corresponding to the Data)')\n","ax.legend()\n","ax.set_xlabel('Hippocampus', fontsize=15)\n","ax.set_ylabel('Entorhinal Cortex', fontsize=15)\n","ax.set_zlabel('Probability', fontsize=15)\n","ax.set_title('Alzheimer'' Disease (Case = 2)', fontsize=24)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tBqvsDzH2GLx"},"source":["####**To make a clearer visualization, the probability functions of the three diagnostic groups are combined in one plot.**"]},{"cell_type":"code","metadata":{"id":"ARUHeWNtB8NA"},"source":["from scipy.stats import multivariate_normal\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from mpl_toolkits.mplot3d import axes3d\n","\n","# Setting up the grid\n","x, y = np.mgrid[2000:12000:1, 1000:6000:1]\n","pos = np.dstack((x, y))\n","rv0 = multivariate_normal([np.mean(cognitive_normal[\"Hippocampus\"]), np.mean(cognitive_normal[\"Entorhinal\"])], cog_norm_mult_Sigma)\n","rv1 = multivariate_normal([np.mean(mild_cognitive_impairment[\"Hippocampus\"]), np.mean(mild_cognitive_impairment[\"Entorhinal\"])], mild_cog_impair_mult_Sigma)\n","rv2 = multivariate_normal([np.mean(alzheimers_disease[\"Hippocampus\"]), np.mean(alzheimers_disease[\"Entorhinal\"])], ad_mult_Sigma)\n","\n","\n","# Three-dimensional Plot\n","fig = plt.figure(figsize=(15,10))\n","ax = fig.add_subplot(111, projection='3d')\n","ax.plot_wireframe(x, y, rv0.pdf(pos), rstride=10, cstride=10, alpha=0.05, color='b',label='PDF (Cognitive Normal)')\n","ax.plot_wireframe(x, y, rv1.pdf(pos), rstride=10, cstride=10, alpha=0.05, color='g',label='PDF (Mild Cognitive Impairment)')\n","ax.plot_wireframe(x, y, rv2.pdf(pos), rstride=10, cstride=10, alpha=0.05, color='r',label='PDF (Alzheimer'' Disease)')\n","ax.legend()\n","ax.set_xlabel('Hippocampus', fontsize=15)\n","ax.set_ylabel('Entorhinal Cortex', fontsize=15)\n","ax.set_zlabel('Probability', fontsize=15)\n","ax.set_title('Complete Dataset', fontsize=24)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WSLb5ePbLBHd"},"source":["##**Conclusion and Takeaway**\n","* In a Univariate Normal Distribution, the **mean** and **variance** of the observed samples are parameters which can give a maximum value of the propbability density function (\"maximum likelihood\").\n","* In a Multivariate Normal Distribution, the **mean** and the **covariance** of the observed samples are the parameters which maximime the likelihood function. As shown in the contour density plots, at these values the density of occurrence of the random samples is at its maximum.\n","* **For this particular dataset, it has been shown that as the disease progresses to Alzheimer's disease, the volumes of the hippocampus and entorhinal cortex show a significant decrease. This is a very interesting insight, and I wonder how the deposition of the Amyloid beta in the brain, which is the main biomarker of Alzheimer's disease, affects the shrinkage of the volumes of these regions.**\n","* Overall, this is a very enjoyable experience where we are given the opportunity to handle and interpret data by ourselves. In the process, I also realize that I still need to brush up more on my Python skills.\n"]}]}